# KoHalluLens: LLM Hallucination Evaluation Benchmark in Korean

[HalluLens: LLM Hallucination Benchmark](https://arxiv.org/abs/2504.17550)ë¥¼ í•œêµ­ì–´ adaptationì„ í•˜ì—¬ ëª¨ë¸ì˜ Hallucinationì„ í‰ê°€í•˜ëŠ” ê¸°ëŠ¥ì„ ì¶”ê°€í•©ë‹ˆë‹¤.


### ğŸ“Œ Original Project Links

<p align="left">
  <a href="https://github.com/facebookresearch/HalluLens">
    <img src="https://img.shields.io/badge/GitHub-HalluLens-black?logo=github" alt="GitHub HalluLens"/>
  </a>
  &nbsp;
  <a href="https://arxiv.org/pdf/2504.17550">
    <img src="https://img.shields.io/badge/arXiv-2504.17550-b31b1b.svg" alt="arXiv Paper"/>
  </a>
</p>

**Authors:**  
*Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang,  
Nicola Cancedda, Pascale Fung*

## ğŸ“‘ Table of Contents
* [ğŸ˜µâ€ğŸ’«LLM Hallucination ìœ í˜•](#-LLM-Hallucination-ìœ í˜•)
* [ğŸ§ª ì£¼ìš” í‰ê°€í•­ëª©](#-ì£¼ìš”-í‰ê°€í•­ëª©)
  * [Extrinsic Hallucination](#extrinsic-hallucination)
  * [Intrinsic Hallucination](#intrinsic-hallucination)
* [ğŸš€ ì‹¤í–‰ ë°©ë²• (How to Run)](#ì‹¤í–‰-ë°©ë²•-how-to-run)
* [âš ï¸ Notice](#0ï¸âƒ£-api-setting)
  * [0ï¸âƒ£ API setting](#0ï¸âƒ£-api-setting)
  * [1ï¸âƒ£ ë°ì´í„° ì¤€ë¹„ (Getting ready with data)](#1ï¸âƒ£-ë°ì´í„°-ì¤€ë¹„-getting-ready-with-data)
    * [ğŸ“‚ í•œêµ­ì–´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ](#ğŸ“‚-í•œêµ­ì–´-ë°ì´í„°-ë‹¤ìš´ë¡œë“œ)
    * [ğŸŒ English Data Download](#ğŸŒ-english-data-download)
  * [2ï¸âƒ£ Customization & Configuration](#2ï¸âƒ£-customization--configuration)
  * [3ï¸âƒ£ Troubleshooting](#3ï¸âƒ£-troubleshooting)


## ğŸ˜µâ€ğŸ’« LLM Hallucination ìœ í˜•

<div align="center">
  <img src="assets/hallucination_taxonomy.png" style="width: 50%; margin: 0 auto; padding-top: 10px; padding-bottom: 10px; display: block;" />

  **LLM Hallucination Taxonomy**
</div>

***Extrinsic Hallucination***:
í•™ìŠµ ë°ì´í„°ì™€ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ìƒì„± ê²°ê³¼ë¬¼ì…ë‹ˆë‹¤. ì´ëŠ” ì…ë ¥ëœ ë¬¸ë§¥(context)ì— ì˜í•´ ë’·ë°›ì¹¨ë  ìˆ˜ë„, ë°˜ë°•ë  ìˆ˜ë„ ì—†ìŠµë‹ˆë‹¤. 
ì´ëŸ¬í•œ í™˜ê°ì€ ëª¨ë¸ì´ (ì‘ì—… ì§€ì‹œì— ê¸°ë°˜í•œ ììœ  í˜•ì‹ í…ìŠ¤íŠ¸ ë“±) ìƒˆë¡œìš´ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ì§€ì‹ì˜ ê²©ì°¨ë¥¼ ë©”ìš°ë ¤ í•  ë•Œ ìì£¼ ë°œìƒí•©ë‹ˆë‹¤. 
ì´ëŠ” í•™ìŠµ ë°ì´í„°ë¡œë¶€í„° ì§€ì‹ì„ í¡ìˆ˜í•˜ëŠ” ëª¨ë¸ì˜ í•œê³„ì™€ ìì‹ ì˜ ì§€ì‹ ê²½ê³„ë¥¼ ì¸ì‹í•˜ì§€ ëª»í•˜ëŠ” ëŠ¥ë ¥ì´ ë¶€ì¡±í•¨ì„ ë°˜ì˜í•©ë‹ˆë‹¤.

***Intrinsic Hallucination***: 
**ì…ë ¥ëœ ë¬¸ë§¥(context)**ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ìƒì„± ê²°ê³¼ë¬¼ì…ë‹ˆë‹¤. 
ëª¨ë¸ì´ ì…ë ¥ ë¬¸ë§¥ì„ ì˜¬ë°”ë¥´ê²Œ ì´í•´í•˜ì§€ ëª»í•  ë•Œ, ì…ë ¥ ì§ˆì˜(query)ì™€ ëª¨ìˆœë˜ê±°ë‚˜ ì›ë³¸ ì…ë ¥ ì§ˆì˜ì— ì˜í•´ ë’·ë°›ì¹¨ë˜ì§€ ì•ŠëŠ” ë‚´ìš©ì„ ìƒì„±í•©ë‹ˆë‹¤. 
ì´ëŠ” ì¶”ë¡  ì‹œì (inference-time)ì— ì¼ê´€ì„±ì„ ìœ ì§€í•˜ì§€ ëª»í•˜ëŠ” ëª¨ë¸ì˜ ëŠ¥ë ¥ì´ ë¶€ì¡±í•¨ì„ ë°˜ì˜í•©ë‹ˆë‹¤.

## ğŸ§ª ì£¼ìš” í‰ê°€í•­ëª©
### Extrinsic Hallucination
1. **PreciseWikiQA**: ëª¨ë¸ì´ trainí•œ ë°ì´í„° ë‚´ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ, *ì§§ê³  ì‚¬ì‹¤ í™•ì¸ì„ ìš”êµ¬í•˜ëŠ” ì§ˆì˜*ì— ëŒ€í•œ ëª¨ë¸ì˜ í™˜ê°(hallucination) ìˆ˜ì¤€ì„ í‰ê°€í•©ë‹ˆë‹¤. ì§ˆë¬¸ì€ í•™ìŠµ ë°ì´í„° ë²”ìœ„ ë‚´ë¡œ í•œì •ë©ë‹ˆë‹¤.
2. **LongWiki**: ëª¨ë¸ì˜ í•™ìŠµ ë°ì´í„° ë‚´ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ *ì¥ë¬¸(long-form) ì½˜í…ì¸  ìƒì„±*ì‹œ ëª¨ë¸ì˜ í™˜ê° ìˆ˜ì¤€ì„ í‰ê°€í•©ë‹ˆë‹¤.
3. **NonExistentRefusal**: ê·¸ëŸ´ë“¯í•˜ê²Œ ë“¤ë¦¬ì§€ë§Œ ì‹¤ì œë¡œëŠ” ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì‚¬ë¡€ì™€ ê°™ì´, *í•™ìŠµ ë°ì´í„° ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ì§€ì‹*ì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì•˜ì„ ë•Œ ëª¨ë¸ì´ í™˜ê° ì •ë³´(ì§€ì–´ë‚¸ ì •ë³´)ë¥¼ ìƒì„±í•  ê°€ëŠ¥ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤. (ì´ë¥¼ ìœ„í•´) ë™ë¬¼, ì‹ë¬¼, ê¸°ì—…, ë¸Œëœë“œ ë“± ë‹¤ì–‘í•œ ì˜ì—­ì—ì„œ ê·¸ëŸ´ë“¯í•˜ê²Œ ë“¤ë¦¬ëŠ”, ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê°œì²´ëª…ì„ ìƒì„±í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëŠ” ë‘ ê°€ì§€ í•˜ìœ„ ì‘ì—…ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤: (i) MixedEntities (ii) GeneratedEntities

<div align="center">
  <img src="assets/main_results.png" style="width: 80%; margin: 0 auto; padding-top: 20px; padding-bottom: 20px; display: block;" />

  **Table 1:** Extrinsic hallucination evaluation results on three HalluLens tasks â€“ PreciseWikiQA, LongWiki, and
NonExistentEntities â€“ in percentage (average of three trials of evaluation). Hallu refers to Hallucinated when not refused, a ratio of answers include incorrect answers when it did not refuse. Correct refers to total correct answer rate, where refusal is considered to be incorrect. False Accept. refers to false acceptance rate, likelihood of model fails to prevent from hallucination on nonexistent entities.
</div>

#### cf) 
- **âš ï¸ì£¼ì˜**: ë³¸ benchmarkëŠ” ëª¨ë¸ì´ Wikipedia ì§€ì‹ì„ í•™ìŠµí–ˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤. ëª¨ë¸ì´ ìœ„í‚¤í”¼ë””ì•„ ì§€ì‹ì„ í•™ìŠµí•˜ì§€ ì•Šì•˜ë‹¤ë©´, í‰ê°€ ê²°ê³¼ê°€ ì™œê³¡ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
- Intrinsic Hallucinationì€ í˜„ì¬ KoHalluLensì—ì„œ ë‹¤ë£¨ì§€ ì•ŠìŠµë‹ˆë‹¤.

---
## ğŸƒ ì‹¤í–‰ ë°©ë²• (How to Run)

### ğŸ› ï¸ Installation
```
git clone https://github.com/facebookresearch/HalluLens.git
cd HalluLens

conda create --name hallulens python==3.12 #3.8.17
conda activate hallulens
```


**[Requriements.txtë¡œ ì„¤ì¹˜ì‹œ]**
```
pip install -r requirements.txt
```

**[uv ì„¤ì¹˜ì‹œ]**
```
pip install uv
uv sync
```


### ğŸ›¢ï¸ Getting ready with data 
We provide script to download all data needed for all three tasks. This code will download all the data that you need for HalluLens. All data will be downloded under the ``/data`` folder. 

#### âš ï¸ ë°ì´í„° ì¤€ë¹„ì‹œ ì°¸ê³ ì‚¬í•­
Wikipedia dump is large (~16GB), so please make sure you have enough space. And it may not be able to download from this codes. <br />
**ì°¸ê³ **: en-wiki-20230401.db íŒŒì¼ì€ ì§ì ‘ ë‹¤ìš´ë¡œë“œ í›„ ì§€ì • ê²½ë¡œì— ë„£ì–´ì£¼ì…”ì•¼ í•©ë‹ˆë‹¤. (ìƒì„¸ ë‚´ìš©ì€ ì•„ë˜ ['í•œêµ­ì–´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ'](#notice) ì°¸ê³ )

```
bash scripts/download_data.sh
```

It include as follow:
- [Wikirank](https://wikirank-2024.di.unimi.it/)
- [GoodWiki](https://huggingface.co/datasets/euirim/goodwiki)
- Processed Wikipedia dump (from [FactScore](https://arxiv.org/abs/2305.14251))
- [ITIS taxonomy](https://www.itis.gov/)
- [250k Medicines Usage, Side Effects and Substitutes](https://www.kaggle.com/datasets/shudhanshusingh/250k-medicines-usage-side-effects-and-substitutes)


### Getting ready with LLM inference.
##### [Together ai setup]
- togther ai api key `.env` íŒŒì¼ì— ì„¤ì •
- `inference_method` íŒŒë¼ë¯¸í„°ë¥¼ `'together'`ë¡œ ì„¤ì •

#### [VLLM inference setup]

Set up your own inference method and replace it in function custom_api ``utils/lm.py``

* For our experiments, we used model checkpoints from Huggingface and hosted through vLLM package -- which you can directly use the default setup call_vllm_api. Refer to [VLLM blog](https://blog.vllm.ai/2024/07/23/llama31.html) for details. For example:

``` 
vllm serve meta-llama/Llama-3.1-405B-Instruct-FP8 --tensor-parallel-size 8
```
<!-- vllm serve meta-llama/-Llama-3.1-8B-Instruct --dtype=half --max-model-len 10000 -->

* We have set the test set prompt generators and LLM evaluator to be same as our experiment set ups. We recommend to use same set up to replicate the results.


### ğŸ”¬ Run Evaluation  

### Overview
All scripts for each task is in scripts. There are mainly three steps for each tasks:

1. `do_generate_prompt` : It generates test prompt for each task under the folder of data
2. `do_inference`: This argument enables the inference of your model
3. `do_eval`: Evalaution for each tasks.

By default, all three steps will be conducted when you run the scripts below. If you want the separate step, you can comment out the step you want to skip. 

### Task 1: PreciseWikiQA
> ``tasks/shortform/precise_wikiqa.py``
```
bash scripts/task1_precisewikiqa.sh
```

### Task 2: LongWiki
> ``tasks/longwiki/longwiki_main.py``
```
bash scripts/task2_longwiki.sh
```

### Task 3: NonExistentRefusal
There are two subtasks:

(1) MixedEntities 
> ``tasks/refusal_test/nonsense_mixed_entities.py``
```
bash scripts/task3-1_mixedentities.sh
```
(2) GeneratedEntities
> ``tasks/refusal_test/round_robin_nonsene_name.py``
#### Prerequisite: set your keys for BRAVE_API_KEY and OPENAI_KEY.
* Note: We used [Brave Search API](https://brave.com/search/api/) for search function. You can either use it with your own access key or your preferred API.

```
bash scripts/task3-2_generatedentities.sh
```

----
## âš ï¸ Notice

### (0) API setting
#### [Mandatory]
1. together ai api
2. brave search api
3. openai api

#### [Optional]
- Anthropic ai api
- grok api
- other api keys for custom llm hosting

### (1) ë°ì´í„° ì¤€ë¹„ (Getting ready with data)

  - **ë°ì´í„° ë‹¤ìš´ë¡œë“œ**

      - **â­ï¸ ì¤‘ìš”\!\!**: `donwload.sh`ë¡œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œ `enwiki-20230401.db` íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ë°›ì•„ì§€ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
      - ì‹¤íŒ¨ì‹œ **[ì´ ë§í¬](https://drive.google.com/uc?id=1mekls6OGOKLmt7gYtHs0WGf5oTamTNat)** ì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œí•´ ì£¼ì„¸ìš”. 20GBë¡œ ë§¤ìš° í½ë‹ˆë‹¤. 
      - ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼ì€ ë°˜ë“œì‹œ ë‹¤ìŒ ê²½ë¡œ(defalut pathì„)ì— ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤.
          - **ê²½ë¡œ**: `hallulens/data/wiki_data/.cache/enwiki-20230401.db`

  - **Data Download**

      - We provide a script to download all data needed for the three tasks. This will download all necessary data into the `/data` folder.
      - **âš ï¸Notice**: The Wikipedia dump is large (\~16GB), so please ensure you have enough space. The download may fail via the script.
        ```bash
        bash scripts/download_data.sh
        ```
      - This script includes:
          - [Wikirank](https://wikirank-2024.di.unimi.it/)
          - [GoodWiki](https://huggingface.co/datasets/euirim/goodwiki)
          - Processed Wikipedia dump (from [FactScore](https://arxiv.org/abs/2305.14251))
          - [ITIS taxonomy](https://www.itis.gov/)
          - [250k Medicines Usage, Side Effects and Substitutes](https://www.kaggle.com/datasets/shudhanshusingh/250k-medicines-usage-side-effects-and-substitutes)

### (2) Customization & Configuration

  - **VLLM ì‚¬ìš© ë° ëª¨ë¸ ë³€ê²½**:
      - `inference_method` íŒŒë¼ë¯¸í„°ë¥¼ `'vllm'`ìœ¼ë¡œ ë³€ê²½í•˜ê³ , `model`ì— í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ëª…ì„ ì…ë ¥í•˜ì„¸ìš”.
  - **LLM as Judge ë°©ì‹ ë³€ê²½ (VLLM, Custom ë“±)**:
      - ì½”ë“œ ë‚´ `call_together_api` í•¨ìˆ˜ë¥¼ `call_vllm_api` ë˜ëŠ” `custom_api` í•¨ìˆ˜ë¡œ hallulens íŒŒì¼ì—ì„œ ì „ì²´ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤. ì¶”í›„ ë” ìœ ì—°í•œ ì„¤ì • ë°©ë²•ì„ ì œê³µí•  ì˜ˆì •ì…ë‹ˆë‹¤.
  - **ìƒˆë¡œìš´ LLM í˜¸ìŠ¤íŒ… ë°©ì‹ ì¶”ê°€**:
      - `hallulens/utils/lm.py` íŒŒì¼ì˜ `custom_api`ì™€ `generate` í•¨ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì—¬ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### (3) Troubleshooting

  - **Together.ai Rate Limit or gpt Rate Limit**: `OpenAI api`, `together.ai` í˜¸ìŠ¤íŒ… ì‚¬ìš© ì‹œ API ìš”ì²­ ì œí•œ(Rate Limit)ì´ ë°œìƒí•˜ì—¬ ì†ë„ë¥¼ ë‚®ì·„ìŠµë‹ˆë‹¤. `Max_worker` íŒŒë¼ë¯¸í„°ë¥¼ ë†’ì´ê±°ë‚˜ ì§€ì—° ì‹œê°„ì„ ì¤„ì´ë©´ Rate Limitì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  - **ëª¨ë¸ ì‚¬ì´ì¦ˆê°€ ì‘ê±°ë‚˜ ì„±ëŠ¥ ë‚®ì€ ëª¨ë¸ì˜ í‰ê°€ ë¶ˆê°€ëŠ¥ ê°€ëŠ¥ì„±**: ì„±ëŠ¥ì´ ë‚®ì€ ëª¨ë¸ì€ í‰ê°€ ê°€ëŠ¥í•œ ë‹µë³€ í˜•ì‹(ì˜¬ë°”ë¥¸ Json í˜•íƒœ)ì„ ìƒì„±í•˜ì§€ ëª»í•´ `longwiki_qa` ë˜ëŠ” `precise_wikiqa` í‰ê°€ê°€ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  - **`precise_wikiqa` Abstain ë¬¸ì œ**: `precise_wikiqa` íƒœìŠ¤í¬ì—ì„œ ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨ë‚˜ `abstain` ë¬¸ì œê°€ ë°˜ë³µëœë‹¤ë©´, ë¶ˆì™„ì „í•˜ê²Œ ìƒì„±ëœ `output` í´ë”ì˜ ëŒ€ìƒ ëª¨ë¸ ê²°ê³¼ë¬¼(.jsonl íŒŒì¼)ì„ ì‚­ì œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”. ì´ì „ì˜ ì˜ëª»ëœ ê²°ê³¼ë¬¼ì„ ê³„ì† ì°¸ì¡°í•˜ì—¬ ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ“œ Citation
```
@article{bang2025hallulens,
      title={HalluLens: LLM Hallucination Benchmark}, 
      author={Yejin Bang and Ziwei Ji and Alan Schelten and Anthony Hartshorn and Tara Fowler and Cheng Zhang and Nicola Cancedda and Pascale Fung},
      year={2025},
      eprint={2504.17550},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2504.17550}, 
}
```

## ğŸªª License

The majority of HalluLens is licensed under CC-BY-NC. However, portions of the project are available under separate license terms:

  - [FActScore](https://github.com/shmsw25/FActScore) is licensed under the MIT license.
  - VeriScore is licensed under the Apache 2.0 license.
